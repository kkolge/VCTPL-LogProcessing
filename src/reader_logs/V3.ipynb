{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d63b7814-a4bc-451f-9325-fb8bc54df4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "\n",
    "TIME_GAP = timedelta(minutes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ec5f368-f427-4966-9602-0f2cce54d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_to_df(filename):\n",
    "    \"\"\"This function takes a file name as an input and loads it into a dataframe\n",
    "    and returns a dataframe\"\"\"\n",
    "    try:\n",
    "        df_file = pd.read_csv(filename,\n",
    "                              sep=\" : \",\n",
    "                              header=None,\n",
    "                              names=[\"Reader_IP\", \"Tag ID\", \"TEMP\"], engine=\"python\")\n",
    "    except FileNotFoundError as fnfe:\n",
    "        df_file = None\n",
    "        print(f\"{filename} not found. Please check the folder selection and try again\")\n",
    "\n",
    "    if df_file is not None:\n",
    "        df_file.head()\n",
    "\n",
    "    return df_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "005f7d79-1f72-414c-bcc5-6fc716ef3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \"\"\"\n",
    "        Following steps will be performed to process the data\n",
    "        1. initialize a list to hold the final set of rows\n",
    "        2. initialize paramerets that need to follow the loop for comparision\n",
    "        2.1 tag_id\n",
    "        2.2 groups\n",
    "        3. read a row\n",
    "        4. check if the tag id is same as last row. if not, create a new group\n",
    "        5. \n",
    "    \"\"\"\n",
    "    tag_id = None\n",
    "    reader_id = None\n",
    "    max_rssi = None\n",
    "    min_timestamp = None\n",
    "    max_timestamp = None\n",
    "    tag_reader_group = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Handling first row\n",
    "        if row[\"Tag ID\"] is None and row[\"Reader_IP\"] is None:\n",
    "            tag_id = row[\"Tag ID\"]\n",
    "            reader_id = row[\"Reader_IP\"]\n",
    "            max_rssi = 0.0\n",
    "            min_timestamp = row[\"TimeStamp\"]\n",
    "            max_timestamp = row[\"TimeStamp\"]\n",
    "            continue\n",
    "\n",
    "        # Handling other rows\n",
    "        if row[\"Tag ID\"] == tag_id:\n",
    "            if row[\"Reader_IP\"] == reader_id:\n",
    "                if row[\"TimeStamp\"] < min_timestamp:\n",
    "                    min_timestamp = row[\"TimeStamp\"]\n",
    "                if row[\"TimeStamp\"] > max_timestamp:\n",
    "                    if row[\"TimeStamp\"] - max_timestamp > TIME_GAP:\n",
    "                        tag_reader_group.append([tag_id, reader_id, min_timestamp, max_timestamp, max_rssi])\n",
    "                        tag_id = row[\"Tag ID\"]\n",
    "                        reader_id = row[\"Reader_IP\"]\n",
    "                        max_rssi = 0.0\n",
    "                        min_timestamp = row[\"TimeStamp\"]\n",
    "                        max_timestamp = row[\"TimeStamp\"]\n",
    "                    else:\n",
    "                        max_timestamp = row[\"TimeStamp\"]\n",
    "                if row[\"RSSI\"] > max_rssi:\n",
    "                    max_rssi = row[\"RSSI\"]\n",
    "            else:\n",
    "                tag_reader_group.append([tag_id, reader_id, min_timestamp, max_timestamp, max_rssi])\n",
    "                reader_id = row[\"Reader_IP\"]\n",
    "                max_rssi = 0.0\n",
    "                min_timestamp = row[\"TimeStamp\"]\n",
    "                max_timestamp = row[\"TimeStamp\"]\n",
    "        else:\n",
    "            tag_reader_group.append([tag_id, reader_id, min_timestamp, max_timestamp, max_rssi])\n",
    "            tag_id = row[\"Tag ID\"]\n",
    "            reader_id = row[\"Reader_IP\"]\n",
    "            max_rssi = 0.0\n",
    "            min_timestamp = row[\"TimeStamp\"]\n",
    "            max_timestamp = row[\"TimeStamp\"]\n",
    "\n",
    "    print(f\"Total unique rows found: {len(tag_reader_group)}\")\n",
    "    return tag_reader_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c49010d3-54f0-4e56-98cd-8751dbfcd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2(df):\n",
    "    \"\"\"\n",
    "        Following steps will be performed to process the data\n",
    "        1. initialize a list to hold the final set of rows\n",
    "        2. initialize paramerets that need to follow the loop for comparision\n",
    "        2.1 tag_id\n",
    "        2.2 groups\n",
    "        3. read a row\n",
    "        4. check if the tag id is same as last row. if not, create a new group\n",
    "        5. \n",
    "    \"\"\"\n",
    "    tag_id = None\n",
    "    reader_id = None\n",
    "    max_rssi = None\n",
    "    min_timestamp = None\n",
    "    max_timestamp = None\n",
    "    tag_reader_group = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Handling first row\n",
    "        if row[\"Tag ID\"] is None and row[\"Reader_IP\"] is None:\n",
    "            tag_id = row[\"Tag ID\"]\n",
    "            reader_id = row[\"Reader_IP\"]\n",
    "            max_rssi = 0.0\n",
    "            min_timestamp = row[\"TimeStamp\"]\n",
    "            max_timestamp = row[\"TimeStamp\"]\n",
    "            continue\n",
    "\n",
    "        # Handling other rows\n",
    "        if row[\"Tag ID\"] == tag_id:\n",
    "            #if row[\"Reader_IP\"] == reader_id:\n",
    "            if row[\"TimeStamp\"] < min_timestamp:\n",
    "                min_timestamp = row[\"TimeStamp\"]\n",
    "            if row[\"TimeStamp\"] > max_timestamp:\n",
    "                if row[\"TimeStamp\"] - max_timestamp > TIME_GAP:\n",
    "                    tag_reader_group.append([tag_id, reader_id, min_timestamp, max_timestamp, max_rssi])\n",
    "                    tag_id = row[\"Tag ID\"]\n",
    "                    reader_id = row[\"Reader_IP\"]\n",
    "                    max_rssi = 0.0\n",
    "                    min_timestamp = row[\"TimeStamp\"]\n",
    "                    max_timestamp = row[\"TimeStamp\"]\n",
    "                else:\n",
    "                    max_timestamp = row[\"TimeStamp\"]\n",
    "            if row[\"RSSI\"] > max_rssi:\n",
    "                max_rssi = row[\"RSSI\"]\n",
    "            # else:\n",
    "            #     tag_reader_group.append([tag_id, reader_id, min_timestamp, max_timestamp, max_rssi])\n",
    "            #     reader_id = row[\"Reader_IP\"]\n",
    "            #     max_rssi = 0.0\n",
    "            #     min_timestamp = row[\"TimeStamp\"]\n",
    "            #     max_timestamp = row[\"TimeStamp\"]\n",
    "        else:\n",
    "            tag_reader_group.append([tag_id, reader_id, min_timestamp, max_timestamp, max_rssi])\n",
    "            tag_id = row[\"Tag ID\"]\n",
    "            reader_id = row[\"Reader_IP\"]\n",
    "            max_rssi = 0.0\n",
    "            min_timestamp = row[\"TimeStamp\"]\n",
    "            max_timestamp = row[\"TimeStamp\"]\n",
    "\n",
    "    print(f\"Total unique rows found: {len(tag_reader_group)}\")\n",
    "    return tag_reader_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1170099-d8e8-4147-9372-6dfe4be57a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocess(df):\n",
    "    # processing the dataframe to get the relevant data in the format that can be processed\n",
    "    df[[\"RSSI\", \"Date\", \"Time\", \"AMPM\"]] = df[\"TEMP\"].str.split(\" \", expand=True)\n",
    "    df[\"TimeStamp\"] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format=\"%m/%d/%Y %H:%M:%S\")\n",
    "    df = df.drop(labels=[\"Date\", \"Time\", \"AMPM\", \"TEMP\"], axis=1)\n",
    "    \n",
    "    df.sort_values(by=[\"Tag ID\", \"Reader_IP\", \"TimeStamp\"])\n",
    "    df.reset_index()\n",
    "\n",
    "    # df_by_group = df.groupby(by=[\"Tag ID\", \"Reader_IP\"], sort=True, group_keys=True)\n",
    "    # df_by_group = df.groupby(by=[\"Tag ID\", \"Reader_IP\"], sort=True, group_keys=True)\n",
    "\n",
    "    # return df_by_group\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0afe360e-6aaa-4e90-8dac-4ee50d66c570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane3/Rfid_Reader_Data_06-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane3/Rfid_Reader_Data_07-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane5/Rfid_Reader_Data_06-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane5/Rfid_Reader_Data_07-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane2/Rfid_Reader_Data_06-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane2/Rfid_Reader_Data_07-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane1/Rfid_Reader_Data_06-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane1/Rfid_Reader_Data_07-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane4/Rfid_Reader_Data_06-02-2024.txt', '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane4/Rfid_Reader_Data_07-02-2024.txt']\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane3/Rfid_Reader_Data_06-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane3/Rfid_Reader_Data_07-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane5/Rfid_Reader_Data_06-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane5/Rfid_Reader_Data_07-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane2/Rfid_Reader_Data_06-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane2/Rfid_Reader_Data_07-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane1/Rfid_Reader_Data_06-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane1/Rfid_Reader_Data_07-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane4/Rfid_Reader_Data_06-02-2024.txt\n",
      "Start importing file /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/Lane4/Rfid_Reader_Data_07-02-2024.txt\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 865433 entries, 0 to 865432\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   Reader_IP  865433 non-null  object        \n",
      " 1   Tag ID     865432 non-null  object        \n",
      " 2   RSSI       865433 non-null  object        \n",
      " 3   TimeStamp  865433 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 26.4+ MB\n",
      "Total unique rows found: 3513\n",
      "Processing completed\n",
      "filename: /home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/\\results.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/home/ketan/repos/ibTrack/VCTPL/LogProcessing/src/reader_logs/7Feb/toProcess/'\n",
    "res = glob.glob(f\"{folder_path}/**/*.txt\", recursive=True)\n",
    "print(res)\n",
    "\n",
    "df_all_files = pd.DataFrame()\n",
    "for file in res:\n",
    "    print(f\"Start importing file {file}\")\n",
    "    df_all_files = pd.concat([df_all_files, load_file_to_df(file)],\n",
    "                             axis=0,\n",
    "                             ignore_index=True)\n",
    "\n",
    "df_processed = df_preprocess(df_all_files)\n",
    "df_processed.info()\n",
    "df_processed[\"RSSI\"] = df_processed[\"RSSI\"].astype(float)\n",
    "df_processed['TimeStamp'] = pd.to_datetime(df_processed['TimeStamp'])\n",
    "df_processed = df_processed.sort_values([\"Tag ID\", \"Reader_IP\", \"TimeStamp\"])\n",
    "\n",
    "result_list = process(df_processed)\n",
    "# [print(row) for row in result_list]\n",
    "\n",
    "fields = [\"Tag ID\", \"Reader IP\", \"Min Timestamp\", \"Max Timestamp\", \"Max RSSI\"]\n",
    "with open(\"results-7Feb.csv\", 'w') as f:\n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL, escapechar=\"\\\\\" )     \n",
    "    write.writerow(fields)\n",
    "    write.writerows(result_list)\n",
    "\n",
    "print (\"Processing completed\")\n",
    "print(f\"filename: {folder_path}\\\\results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fd12b-63dc-4be6-877b-8c610a644715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
